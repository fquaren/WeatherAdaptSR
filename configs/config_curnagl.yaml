experiment:
  name: "cross-val-v3" # "cross-val-v3", "debugging"
  save_dir: "/scratch/fquareng/experiments"
  device: "cuda"  # "cuda" or "cpu"
  model: UNet
  # UNet
  # UNet_BN
  # UNet_DO
  # UNet_DO_BN
  # UNet_Noise
  # UNet_Noise_DO_BN
  # UNet_Trainable_Noise

paths:
  local_dir: "/work/FAC/FGSE/IDYST/tbeucler/downscaling/fquareng/WeatherAdaptSR"
  data_path: "/work/FAC/FGSE/IDYST/tbeucler/downscaling/fquareng/data/clusters"
  elev_path: "/work/FAC/FGSE/IDYST/tbeucler/downscaling/fquareng/data/dem_squares"
  clusters: [
    "cluster_0",
    "cluster_1",
    "cluster_2",
    "cluster_3",
    "cluster_4",
    "cluster_5",
    "cluster_6",
    "cluster_7",
    "cluster_8",
    "cluster_9",
    "cluster_10",
    "cluster_11"
  ]

training:
  num_epochs: 25
  batch_size: 16
  use_theta_e: False
  load_data_on_gpu: True
  num_workers: 0  # 0 if on GH200
  early_stopping: True
  early_stopping_params:
    patience: 10
  criterion: MSELoss
  optimizer: Adam
  # optimizer_params:
  #   lr: 0.0005
  #   weight_decay: 0.0001
  scheduler: ReduceLROnPlateau
  scheduler_params:
    mode: "min"
    factor: 0.5
    patience: 5
    verbose: True

testing:
  criterion: MSELoss

optimization:
  num_epochs: 5  # 0 if not optimizing, 10 if optimizing
  num_trials: 5

domain_specific:
  cluster_0:
    optimizer_params:
      lr: 3.224280188805708e-05
      weight_decay: 5.0245053055189817e-05
      batch_size: 16
  cluster_1:
    optimizer_params:
      lr: 3.224280188805708e-05
      weight_decay: 5.0245053055189817e-05
      batch_size: 16
  cluster_2:
    optimizer_params:
      lr: 3.224280188805708e-05
      weight_decay: 5.0245053055189817e-05
      batch_size: 16
  cluster_3:
    optimizer_params:
      lr: 3.224280188805708e-05
      weight_decay: 5.0245053055189817e-05
      batch_size: 16
  cluster_4:
    optimizer_params:
      lr: 3.224280188805708e-05
      weight_decay: 5.0245053055189817e-05
      batch_size: 16
  cluster_5:
    optimizer_params:
      lr: 3.224280188805708e-05
      weight_decay: 5.0245053055189817e-05
      batch_size: 16
  cluster_6:
    optimizer_params:
      lr: 3.224280188805708e-05
      weight_decay: 5.0245053055189817e-05
      batch_size: 16
  cluster_7:
    optimizer_params:
      lr: 3.224280188805708e-05
      weight_decay: 5.0245053055189817e-05
      batch_size: 16
  cluster_8:
    optimizer_params:
      lr: 3.224280188805708e-05
      weight_decay: 5.0245053055189817e-05
      batch_size: 16
  cluster_9:
    optimizer_params:
      lr: 3.224280188805708e-05
      weight_decay: 5.0245053055189817e-05
      batch_size: 16
  cluster_10:
    optimizer_params:
      lr: 3.224280188805708e-05
      weight_decay: 5.0245053055189817e-05
      batch_size: 16
  cluster_11:
    optimizer_params:
      lr: 3.224280188805708e-05
      weight_decay: 5.0245053055189817e-05
      batch_size: 16