experiment:
  seed: 0
  name: "UNet8x_MDAN"  # "UNet_MMD, "UNet_baseline_v2" # "training_on_individual_clusters" #"UNet-8x-baseline-T2M", "finetuning"
  save_dir: "/scratch/fquareng/experiments"
  device: "cuda"  # "cuda" or "cpu"
  model: UNet8x_MDAN  # UNet8x, UNet8x_BN, UNet8x_DO, UNet8x_DO_BN, UNet8x_Noise, UNet8x_MDAN, UNet8x_MMD

data:
  data_path: "/work/FAC/FGSE/IDYST/tbeucler/downscaling/fquareng/data"
  input_path: "DA/1d-PS-RELHUM_2M-T_2M_cropped_gridded_clustered_threshold_12_blurred"
  target_path: "DA/1d-PS-RELHUM_2M-T_2M_cropped_gridded_clustered_threshold_12"
  dem_path: "dem_squares"
  variable: "T_2M"

training:
  num_epochs: 40
  batch_size: 64
  num_workers: 24  # set to 1 if training in curnagl, max=72
  early_stopping: True
  early_stopping_params:
    patience: 10
  criterion: MSELoss
  optimizer: AdamW
  optimizer_params:
    lr: 0.00001
    weight_decay: 0.0001
  scheduler: ReduceLROnPlateau
  scheduler_params:
    mode: "min"
    factor: 0.5
    patience: 3
    cooldown: 2
    verbose: True
  domain_adaptation: 
    mdan_criterion: CrossEntropyLoss
    mu: 0.01  # tune it from 0.01 to 1 (balances regression and domain loss)
    gamma: 1  # tune it from 1 to 5  (controls logsumexp smoothing)
    lambda_max: 1

testing:
  criterion: MSELoss
